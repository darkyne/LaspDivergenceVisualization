TODO:

-Fake app qui peut run sur les nodes pour générer des valeurs et utiliser un CRDT.
-Script permettant de simuler des partitions.
-Implémentation du ORSWOT sur base du ORSET. FINALEMENT DEJA FOURNIS!
==================================================================================================================================
==================================================================================================================================
FAKE APP:

Remarque: le node sur lequel on join aura tendance à converger plus vite que les autres.

J'ai une fonction 			
launchExperiment(ExperimentNumber, NodeToJoin, CRDT_Id, CRDT_Type, CRDT_Type_String, TotalNumberOfNodes, SendingSpeed, NumberOfValues, GeneratingUnderPartition)

Voici sa spec:

%Launch an experiment for the current node
% IN:
%Specify a number for the experiment (used to write the result file)
%Specify the node to join to create the cluster
%Specify a CRDT_ID (format as <<"setX">>)
%Specify a CRDT_Type (ex: state_orset)
%Specify the CRDT_Type as a string (ex: "state_orset", it's used to write the result file)
%Specify the Total Number of Nodes taking part of the experiment
%Specify the Sending Speed (as the number of ms between each send, considering one node), 0 means the fastest possible
%Specify the Number of Values each node will have to generate and send on the CRDT
%Specify (with a boolean) if you want the node to join the cluster then generate and send values. Or rather generate and send values on the isolated CRDT (as if it was under partition) then join.
% OUT:
%The node will generate the number of values and send them, trying to achieve the specified Sending Speed.
%It will join the cluster before or after sending the values based on GeneratingUnderPartition
%The time required to generate and send the values, the time required after the generation to reach convergence and all the paramters are written to a file
%The file name will be in the folder /lasp/Memoire/Mesures with the name Exp+ExperimentNumber+_Node+TheActualNodeId

Elle fonctionne pour l'instant.
Petits défauts:
La vitesse à laquelle les datas sont envoyés sont influencés par la vitesse donnée en argument mais n'envoit pas précisément à cette vitesse car il y a des ralentissements dûs à la machine.
Cela n'influence pas les mesures obtenues.

INFO IMPORTANTE:
La réelle mesure du temps pour converger (cas partition false) = EllapsedTime + RequiredTimeToSend - MaximumRequiredTimeToSend(biggest from all nodes).
Comme ça, on a bien le temps entre le moment où tous les nodes ont envoyés leurs données et le moment où le node a bien récupéré toutes les données du cluster.
Cela nécessite donc d'analyser l'ensemble des fichiers d'une expérience (regarder chaque node) pour pouvoir finalement calculer les convergence time.

REMARQUES: 
Quand le cluster comporte beaucoup de nodes, la disparité entre les nodes grandit énormément. Par exemple avec un cluster de 20 nodes, où chaque node génère 100values et on attend que le node récupère les 2.000 values:
Ils vont convergés par vague. Par exemple au bout de 10 secondes, 10 nodes vont converger. Puis il faudra par exemple 10 seconde de plus pour que les 10 nodes suviantes convergent d'un coup.
En gros je pense qu'il y a un petit broadcast (par exemple aux voisins proches) quand un node converge, ce qui fait qu'ils convergent par vague. Pour un petit nombre de nodes, ils convergent tous en même temps du coup.

10 nodes locaux: ils convergent tous d'un coup. Et ce, que je join avant ou après de send les values.

TODO pour dimanche: Ajouter des experiences avec des removes.
Faire en sorte que ça ne fasse que du aw_set. Il n'y a pas besoin de considérer aussi les orset, je pense.
==================================================================================================================================
==================================================================================================================================
Injection de partition:
Je join avant de générer et envoyer les values pour faire qu'il n'y ai pas de partition.
Je peux aussi générer et envoyer les values puis join, ce qui revient à être sous partition pendant l'envoi des données.
Le fait de jouer sur le fait de join ou quit le cluster permet, je pense, de simuler une partition.




